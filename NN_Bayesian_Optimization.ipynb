{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP1cIdhHRSlnWJf4Ybub6sD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shobha-nosimpler/Neural_Network/blob/main/NN_Bayesian_Optimization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6gw_TRqvJYLN"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "NCSY0owkJnqd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Here's a brief example of how you can use Bayesian Optimization for tuning the hyperparameters of a simple neural network using the 'skopt' library, Scikit-Optimize, in Python"
      ],
      "metadata": {
        "id": "CMTk01S9Jn4o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import the libraries\n",
        "from skopt\n",
        "- skopt.space Real, Integer\n",
        "- skopt.utils use_named_args\n",
        "- skopt gp_minimize\n",
        "\n",
        "from sklearn\n",
        "- sklearn.datasets load_breast_cancer\n",
        "- sklearn.model_selection train_test_split\n",
        "- sklearn.preprocessing StandardScaler\n",
        "- sklearn.neural_network MPLClassifier\n",
        "- sklearn.metrics accuracy_score"
      ],
      "metadata": {
        "id": "aNU6OlDSKSsO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-optimize"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z2sNT1COPxhT",
        "outputId": "70ccf080-cbcd-4ae6-a612-8e8fd983b4f3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scikit-optimize\n",
            "  Downloading scikit_optimize-0.10.2-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (1.4.2)\n",
            "Collecting pyaml>=16.9 (from scikit-optimize)\n",
            "  Downloading pyaml-24.7.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: numpy>=1.20.3 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (1.3.2)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (24.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from pyaml>=16.9->scikit-optimize) (6.0.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.0->scikit-optimize) (3.5.0)\n",
            "Downloading scikit_optimize-0.10.2-py2.py3-none-any.whl (107 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.8/107.8 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyaml-24.7.0-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: pyaml, scikit-optimize\n",
            "Successfully installed pyaml-24.7.0 scikit-optimize-0.10.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from skopt import gp_minimize\n",
        "from skopt.space import Real, Integer\n",
        "from skopt.utils import use_named_args\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "dMfmRaWFJoOj"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 1 : Data Loading and Preprocessing\n",
        "- We load the breast cancer data and split it into training & testing sets\n",
        "- The data is then scaled using 'StandardScaler'"
      ],
      "metadata": {
        "id": "WifRfWmTLdeS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and preprocess data\n",
        "data = load_breast_cancer()"
      ],
      "metadata": {
        "id": "sJtDSfq0POr7"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w65TAeDXPYPb",
        "outputId": "df1b1aba-07c6-4ed0-d385-fa1ffc9f88ef"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'sklearn.utils._bunch.Bunch'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(data.keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zh2vaWKZT7rW",
        "outputId": "56d3e9b2-ece8-432b-c1b6-704a1bca8a1f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename', 'data_module'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(data.data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Af2R5piSMIU",
        "outputId": "b6ee1969-d15e-42cd-fc0b-17fb50cf0959"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.ndarray'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(data.data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N9cuFiwHTzA4",
        "outputId": "19d17e87-71ef-47aa-84b7-7fef02883c94"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(569, 30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(data.target_names)\n",
        "print(data.feature_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u9tf2VEEUCmC",
        "outputId": "0129fc96-91e6-4bfd-f1c3-5e323b227b88"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['malignant' 'benign']\n",
            "['mean radius' 'mean texture' 'mean perimeter' 'mean area'\n",
            " 'mean smoothness' 'mean compactness' 'mean concavity'\n",
            " 'mean concave points' 'mean symmetry' 'mean fractal dimension'\n",
            " 'radius error' 'texture error' 'perimeter error' 'area error'\n",
            " 'smoothness error' 'compactness error' 'concavity error'\n",
            " 'concave points error' 'symmetry error' 'fractal dimension error'\n",
            " 'worst radius' 'worst texture' 'worst perimeter' 'worst area'\n",
            " 'worst smoothness' 'worst compactness' 'worst concavity'\n",
            " 'worst concave points' 'worst symmetry' 'worst fractal dimension']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(data.target))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qMYm4ao6TScF",
        "outputId": "91579fe4-31ec-460e-e2ff-c1e68c980e1c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.ndarray'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(data.data[0].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5rHuouVuUsI1",
        "outputId": "7046690d-8d1e-4d91-ecc5-c0eb70b0a41c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(30,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# first row data for 30 features\n",
        "print(data.data[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yKwgJnVhUkkv",
        "outputId": "547e80b8-2ef5-4d20-f9c9-a32eb2e168f6"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1.799e+01 1.038e+01 1.228e+02 1.001e+03 1.184e-01 2.776e-01 3.001e-01\n",
            " 1.471e-01 2.419e-01 7.871e-02 1.095e+00 9.053e-01 8.589e+00 1.534e+02\n",
            " 6.399e-03 4.904e-02 5.373e-02 1.587e-02 3.003e-02 6.193e-03 2.538e+01\n",
            " 1.733e+01 1.846e+02 2.019e+03 1.622e-01 6.656e-01 7.119e-01 2.654e-01\n",
            " 4.601e-01 1.189e-01]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# split the data which is numpy array of shape (569,30) : 80 percet Train and 20 percent Test\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "mFkEu6VfUohA"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3aP3_cClUon5",
        "outputId": "861a9c65-c174-4c9a-ae06-7f3c276c23ca"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(455, 30)\n",
            "(114, 30)\n",
            "(455,)\n",
            "(114,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train[0])\n",
        "print(y_train[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J9Ov4jw5Uosy",
        "outputId": "231ad473-2c31-4df8-9e69-de3308accbe5"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[9.029e+00 1.733e+01 5.879e+01 2.505e+02 1.066e-01 1.413e-01 3.130e-01\n",
            " 4.375e-02 2.111e-01 8.046e-02 3.274e-01 1.194e+00 1.885e+00 1.767e+01\n",
            " 9.549e-03 8.606e-02 3.038e-01 3.322e-02 4.197e-02 9.559e-03 1.031e+01\n",
            " 2.265e+01 6.550e+01 3.247e+02 1.482e-01 4.365e-01 1.252e+00 1.750e-01\n",
            " 4.228e-01 1.175e-01]\n",
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.unique(y_train))\n",
        "print(np.unique(y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zsMoVT9cXJl-",
        "outputId": "76249265-d9a4-48d9-c066-df6ce05cd272"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 1]\n",
            "[0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Standardise the train and test data\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "HkMY1icJXubH"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print the first row for the train and test data after scaling\n",
        "print(X_train[0])\n",
        "print(X_test[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LylFmMsLXunW",
        "outputId": "47faf458-714f-49c9-e1c0-2f2a2df4aa56"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-1.44075296 -0.43531947 -1.36208497 -1.1391179   0.78057331  0.71892128\n",
            "  2.82313451 -0.11914956  1.09266219  2.45817261 -0.26380039 -0.01605246\n",
            " -0.47041357 -0.47476088  0.83836493  3.25102691  8.43893667  3.39198733\n",
            "  2.62116574  2.06120787 -1.23286131 -0.47630949 -1.24792009 -0.97396758\n",
            "  0.72289445  1.18673232  4.67282796  0.9320124   2.09724217  1.88645014]\n",
            "[-0.46649743 -0.13728933 -0.44421138 -0.48646498  0.28085007  0.04160589\n",
            " -0.11146496 -0.26486866  0.41524141  0.13513744 -0.02091509 -0.29323907\n",
            " -0.17460869 -0.2072995  -0.01181432 -0.35108921 -0.1810535  -0.24238831\n",
            " -0.33731758 -0.0842133  -0.2632354  -0.14784208 -0.33154752 -0.35109337\n",
            "  0.48001942 -0.09649594 -0.03583041 -0.19435087  0.17275669  0.20372995]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2: Search Space\n",
        "The hyperparameter space includes:\n",
        "- learning_rate_init : The initial learning rate of training\n",
        "- hidden_layer_sizes : The number of neurons in the hidden_layer(an integer)"
      ],
      "metadata": {
        "id": "dXcxDjB9Zeel"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the hyperparameter search space\n",
        "space = [\n",
        "    Real(1e-6, 1e-2, \"log-uniform\", name='learning_rate_init'),\n",
        "    Integer(1, 200, name='hidden_layer_sizes')\n",
        "]"
      ],
      "metadata": {
        "id": "zI4RPgrYYPFC"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(space[0]))\n",
        "print(type(space[1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oIBEA_EjYPON",
        "outputId": "81bd505a-05ac-423d-96bd-44c81dc8731f"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'skopt.space.space.Real'>\n",
            "<class 'skopt.space.space.Integer'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(space[0])\n",
        "print(space[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FeydoXP5YPX2",
        "outputId": "4b1f65f4-785f-465e-bb9b-3d199775326b"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Real(low=1e-06, high=0.01, prior='log-uniform', transform='identity')\n",
            "Integer(low=1, high=200, prior='uniform', transform='identity')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 3: Objective Function\n",
        "- the objective function is defined to minimize the negative accuracy of the neural network\n",
        "- this function will be called during the optimization process"
      ],
      "metadata": {
        "id": "1zKyjnDBbGMJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# What is MLPClassifier : multi-layer perceptron classifier\n",
        "\n",
        "- A multi-layer perceptron (MLP) classifier is a neural network that uses supervised learning to predict the category of an input data point.\n",
        "\n",
        "- MLPs are a type of artificial neural network that consists of multiple layers of neurons, with each layer fully connected to the next.\n",
        "\n",
        "- The neurons in the MLP typically use nonlinear activation functions, which allow the network to learn complex patterns in data\n",
        "\n",
        "- MLPs are a popular choice for machine learning applications because they can handle complex classification tasks, model non-linear relationships, and flexibly handle different data types. For example, MLPs can be used for tasks such as classification, regression, and pattern recognition.\n",
        "\n",
        "- In an MLP, the network is trained using input data as a DataSet and output labels as a LabelSet. The network is then trained to predict the most probable label for a given data point input. For example, the MLP classifier can support multi-class classification by applying Softmax as the output function. The model can also support multi-label classification, where a sample can belong to more than one class.\n",
        "\n",
        "# Difference between neuron and perceptron\n",
        "\n",
        "A neuron and a perceptron are related concepts but not exactly the same:\n",
        "\n",
        "Neuron: In the context of neural networks, a neuron is a basic unit that performs a computation. **It receives inputs, applies a weighted sum, passes it through an activation function, and produces an output.** Neurons are the building blocks of more complex structures like layers and networks.\n",
        "\n",
        "Perceptron: A perceptron is a type of artificial neuron and one of the simplest forms of a neural network. **It is essentially a single-layer neural network with a step activation function. The perceptron was one of the earliest models of a neuron and is typically used for binary classification tasks.**\n",
        "\n",
        "So, while a perceptron is a specific type of neuron, the term \"neuron\" in a broader neural network context refers to a more general concept that includes various types of activation functions and layers, not just the step function used in perceptrons."
      ],
      "metadata": {
        "id": "ZqEJidv5c0M7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the objective function to minimize (negative accuracy)\n",
        "@use_named_args(space)\n",
        "def objective(learning_rate_init, hidden_layer_sizes):\n",
        "    model = MLPClassifier(learning_rate_init=learning_rate_init, hidden_layer_sizes=(hidden_layer_sizes,),\n",
        "                          random_state=42, max_iter=1000)\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    return -accuracy  # Minimize the negative accuracy"
      ],
      "metadata": {
        "id": "4JJog-tBZRnH"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 4 : Bayesian Optimization\n",
        "The 'gp_minimize' function form skopt is used to perform Bayesian optimization searching for the best hyperparameters over 20 calls"
      ],
      "metadata": {
        "id": "OjFMsZS9jFUr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run Bayesian Optimization\n",
        "result = gp_minimize(objective, space, n_calls=20, random_state=42)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wqSBBMmNZLd5",
        "outputId": "3ee34e63-40bf-4e3a-a3b8-3fc0310b2d50"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bayesian optimization took 46 seconds to complete\n"
      ],
      "metadata": {
        "id": "NWO4lVZmjuEL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 6 : Result\n",
        "The best hyperparameters found and the corresponding accuracy are printed\n",
        "\n",
        "This example is a basic illustration. In a real_world scenario you might want to tune additional hyperparmeters and consider a more complex model."
      ],
      "metadata": {
        "id": "f-mGv6jrj60i"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tlxks3c1ZL2B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Output the best hyperparameters and corresponding accuracy\n",
        "print(\"Best hyperparameters:\")\n",
        "print(\"Learning rate:\", result.x[0])\n",
        "print(\"Hidden layer size:\", result.x[1])\n",
        "print(\"Best accuracy:\", -result.fun)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q9xe08-nJob0",
        "outputId": "5e3498df-671f-48ca-e510-c967d84bc228"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best hyperparameters:\n",
            "Learning rate: 0.005678201970293135\n",
            "Hidden layer size: 1\n",
            "Best accuracy: 0.9912280701754386\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1IRGJL5kUWzQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}