# Neural Network Implementation in Python

This repository contains Python code implementing a neural network from scratch. It covers basic concepts and advanced techniques used in deep learning, providing a hands-on approach to understanding how neural networks work.

# Features

-  Custom Neural Network: Implemented using NumPy, showcasing the forward pass, backpropagation, and weight updates.
-  Activation Functions: Includes ReLU, Sigmoid, and Softmax with explanations and use cases.
-  Regularization Techniques: L2 regularization and Dropout are integrated to prevent overfitting.
-  Gradient Descent Optimization: Implements various forms of gradient descent, including SGD and Adam.
-  Example Use Cases: Demonstrates the neural network on classic datasets like MNIST or XOR problem.
